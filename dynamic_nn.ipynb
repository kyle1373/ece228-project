{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA Data:\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2014-05-27  133.089996  134.210007  132.869995  134.169998  115.965096   \n",
      "1  2014-05-28  134.169998  135.149994  134.169998  134.330002  116.103371   \n",
      "2  2014-05-29  134.710007  135.199997  134.429993  135.139999  116.803482   \n",
      "3  2014-05-30  134.669998  135.440002  134.039993  135.250000  116.898544   \n",
      "4  2014-06-02  135.500000  136.029999  134.770004  135.899994  117.460373   \n",
      "\n",
      "    Volume  \n",
      "0  3085500  \n",
      "1  2609400  \n",
      "2  2234100  \n",
      "3  2760300  \n",
      "4  2629900  \n",
      "MSBHF Data:\n",
      "         Date      Open      High       Low     Close  Adj Close  Volume\n",
      "0  2014-05-27  6.466667  6.466667  6.466667  6.466667   4.680295       0\n",
      "1  2014-05-28  6.466667  6.466667  6.466667  6.466667   4.680295       0\n",
      "2  2014-05-29  6.466667  6.466667  6.466667  6.466667   4.680295       0\n",
      "3  2014-05-30  6.466667  6.466667  6.466667  6.466667   4.680295       0\n",
      "4  2014-06-02  6.466667  6.466667  6.466667  6.466667   4.680295       0\n",
      "V Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  53.247501  53.630001  53.205002  53.625000  50.004101  9676800\n",
      "1  2014-05-28  53.625000  53.625000  53.252499  53.450001  49.840908  7223200\n",
      "2  2014-05-29  53.500000  53.672501  53.375000  53.667500  50.043728  5260400\n",
      "3  2014-05-30  53.970001  53.987499  53.332500  53.707500  50.081024  6136400\n",
      "4  2014-06-02  53.842499  53.922501  53.209999  53.380001  49.775646  6364000\n",
      "HCA Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  53.799999  54.000000  53.029999  53.119999  50.034176  1931000\n",
      "1  2014-05-28  53.380001  53.970001  53.180000  53.369999  50.269638  2217600\n",
      "2  2014-05-29  53.369999  53.660000  53.290001  53.389999  50.288483  1737000\n",
      "3  2014-05-30  53.299999  53.520000  52.869999  52.990002  49.911732  2607800\n",
      "4  2014-06-02  53.099998  53.279999  52.369999  52.990002  49.911732  4012900\n",
      "NTDOY Data:\n",
      "         Date   Open   High    Low  Close  Adj Close   Volume\n",
      "0  2014-05-27  2.860  2.872  2.858  2.870      2.870  2270500\n",
      "1  2014-05-28  2.848  2.858  2.842  2.854      2.854  2445000\n",
      "2  2014-05-29  2.884  2.914  2.884  2.908      2.908   300500\n",
      "3  2014-05-30  2.924  2.924  2.892  2.912      2.912    41500\n",
      "4  2014-06-02  2.908  2.918  2.894  2.904      2.904   171000\n",
      "ADM Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  43.650002  44.360001  43.619999  44.320000  33.623043  2400300\n",
      "1  2014-05-28  44.320000  44.549999  44.209999  44.290001  33.600288  1851400\n",
      "2  2014-05-29  44.389999  44.689999  44.349998  44.639999  33.865803  1727300\n",
      "3  2014-05-30  44.560001  44.980000  44.560001  44.939999  34.093399  2011300\n",
      "4  2014-06-02  44.889999  45.049999  44.759998  44.849998  34.025120  2295300\n",
      "LH Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  86.597939  86.924400  86.297249  86.675255  84.231491   575714\n",
      "1  2014-05-28  86.769760  86.778351  85.790375  86.443298  84.006065   561397\n",
      "2  2014-05-29  86.743988  88.410652  86.391754  88.402061  85.909599  1015939\n",
      "3  2014-05-30  88.221649  88.221649  87.646049  88.127151  85.642441   812123\n",
      "4  2014-06-02  88.247421  88.273193  87.551544  87.706184  85.233345   596899\n",
      "BAC Data:\n",
      "         Date   Open   High    Low  Close  Adj Close     Volume\n",
      "0  2014-05-27  15.00  15.31  14.98  15.22  12.499309  125398900\n",
      "1  2014-05-28  15.27  15.28  15.03  15.14  12.433609   72481700\n",
      "2  2014-05-29  15.12  15.21  15.10  15.15  12.441822   39423000\n",
      "3  2014-05-30  15.12  15.23  15.07  15.14  12.433609   45787100\n",
      "4  2014-06-02  15.16  15.28  15.05  15.26  12.532158   46374000\n",
      "IRM Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  27.874308  28.243994  27.846581  28.234751  15.045681  1660113\n",
      "1  2014-05-28  28.188540  28.715342  28.188540  28.502773  15.188508  2422706\n",
      "2  2014-05-29  28.428835  28.733826  28.327171  28.706100  15.296857  1316902\n",
      "3  2014-05-30  28.641405  28.789280  28.548983  28.780037  15.336258  1622784\n",
      "4  2014-06-02  28.780037  28.890944  28.530499  28.789280  15.341183  1519020\n",
      "STZ Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  83.139999  83.919998  83.080002  83.449997  73.873802  1189400\n",
      "1  2014-05-28  83.510002  83.989998  82.660004  83.150002  73.608269  1201100\n",
      "2  2014-05-29  83.209999  84.099998  83.180000  83.779999  74.165939   797400\n",
      "3  2014-05-30  83.660004  84.320000  83.660004  84.129997  74.475777  1045400\n",
      "4  2014-06-02  83.809998  84.070000  83.160004  83.940002  74.307564   831600\n",
      "ULTA Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  85.800003  87.870003  85.790001  87.220001  87.220001   909700\n",
      "1  2014-05-28  87.000000  87.169998  83.760002  85.400002  85.400002  1058500\n",
      "2  2014-05-29  85.699997  85.760002  83.540001  85.029999  85.029999  1084100\n",
      "3  2014-05-30  84.900002  85.389999  84.360001  84.900002  84.900002   677100\n",
      "4  2014-06-02  85.050003  87.269997  84.739998  86.800003  86.800003   730800\n",
      "ARE Data:\n",
      "         Date       Open       High        Low      Close  Adj Close  Volume\n",
      "0  2014-05-27  75.239998  75.309998  74.260002  74.849998  54.667892  590600\n",
      "1  2014-05-28  74.790001  74.930000  74.180000  74.860001  54.675190  454800\n",
      "2  2014-05-29  75.019997  75.529999  74.709999  75.470001  55.120708  188800\n",
      "3  2014-05-30  75.449997  76.279999  75.269997  76.089996  55.573536  521900\n",
      "4  2014-06-02  75.919998  77.080002  75.809998  76.889999  56.157829  348300\n",
      "PEP Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  85.809998  86.629997  85.650002  86.529999  64.866508  4400100\n",
      "1  2014-05-28  86.349998  87.160004  86.339996  87.070000  65.271324  4030700\n",
      "2  2014-05-29  86.989998  87.839996  86.879997  87.730003  65.766083  4647300\n",
      "3  2014-05-30  87.610001  88.480003  87.410004  88.330002  66.215881  5181600\n",
      "4  2014-06-02  88.120003  88.389999  87.760002  87.870003  65.871056  2876100\n",
      "MDLZ Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  37.259998  37.500000  37.250000  37.430000  30.511684   7453100\n",
      "1  2014-05-28  37.410000  37.500000  37.259998  37.400002  30.487234   7596900\n",
      "2  2014-05-29  37.480000  37.490002  37.330002  37.480000  30.552439   6706900\n",
      "3  2014-05-30  37.619999  37.669998  37.320000  37.619999  30.666559  12917000\n",
      "4  2014-06-02  37.540001  37.919998  37.439999  37.770000  30.788845   5895100\n",
      "DLR Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  57.770000  57.869999  57.299999  57.580002  39.097797   927000\n",
      "1  2014-05-28  57.599998  58.000000  57.230000  57.639999  39.138542   964000\n",
      "2  2014-05-29  57.180000  57.610001  56.509998  57.400002  38.975567  1341200\n",
      "3  2014-05-30  57.470001  57.970001  57.279999  57.500000  39.043468  1351500\n",
      "4  2014-06-02  57.540001  58.150002  57.470001  58.099998  39.450886   828700\n",
      "LVMUY Data:\n",
      "         Date       Open       High        Low      Close  Adj Close  Volume\n",
      "0  2014-05-27  39.400002  39.490002  39.320000  39.330002  29.430037   67200\n",
      "1  2014-05-28  39.029999  39.189999  38.980000  39.119999  29.272898   48000\n",
      "2  2014-05-29  39.139999  39.360001  39.099998  39.270000  29.385145   82900\n",
      "3  2014-05-30  39.560001  39.950001  39.450001  39.939999  29.886497   64800\n",
      "4  2014-06-02  39.380001  39.480000  39.209999  39.389999  29.474934   52300\n",
      "MRK Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  54.322517  54.427483  53.883587  54.093510  39.807354   7652286\n",
      "1  2014-05-28  54.112595  54.131680  53.816795  53.816795  39.603710   7171569\n",
      "2  2014-05-29  54.303436  55.143131  54.007633  55.057251  40.516575   8922358\n",
      "3  2014-05-30  54.885494  55.601147  54.885494  55.209923  40.628906  12071912\n",
      "4  2014-06-02  55.257633  55.534351  54.847328  55.276718  40.678089   6733924\n",
      "ORCL Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  42.259998  42.349998  41.730000  41.910000  35.851395  12680200\n",
      "1  2014-05-28  41.990002  42.189999  41.560001  41.570000  35.560547  11308800\n",
      "2  2014-05-29  41.790001  42.209999  41.610001  42.200001  36.099480   9629500\n",
      "3  2014-05-30  42.080002  42.200001  41.849998  42.020000  35.945492  13496500\n",
      "4  2014-06-02  41.959999  42.020000  41.610001  41.970001  35.902721  11284900\n",
      "SBUX Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  36.320000  36.889999  36.270000  36.830002  30.466822  10100400\n",
      "1  2014-05-28  36.650002  36.785000  36.459999  36.634998  30.305504   8210000\n",
      "2  2014-05-29  36.759998  36.779999  36.325001  36.555000  30.239338   6448000\n",
      "3  2014-05-30  36.580002  36.750000  36.264999  36.619999  30.293102   6879200\n",
      "4  2014-06-02  36.610001  37.029999  36.580002  36.924999  30.545401   5926200\n",
      "IPGP Data:\n",
      "         Date       Open       High        Low      Close  Adj Close  Volume\n",
      "0  2014-05-27  62.709999  63.880001  62.709999  63.380001  63.380001  398800\n",
      "1  2014-05-28  63.380001  63.650002  62.779999  62.959999  62.959999  455100\n",
      "2  2014-05-29  63.060001  63.500000  62.680000  62.980000  62.980000  308600\n",
      "3  2014-05-30  62.840000  63.480000  62.509998  63.099998  63.099998  225400\n",
      "4  2014-06-02  63.299999  63.450001  62.630001  63.139999  63.139999  221100\n",
      "PG Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  80.550003  80.580002  80.050003  80.080002  60.229107  7003800\n",
      "1  2014-05-28  80.029999  80.279999  80.019997  80.099998  60.244148  4201400\n",
      "2  2014-05-29  80.099998  80.400002  80.080002  80.400002  60.469772  3886800\n",
      "3  2014-05-30  80.250000  80.849998  80.169998  80.790001  60.763107  7433000\n",
      "4  2014-06-02  80.660004  80.669998  80.290001  80.360001  60.439682  4331700\n",
      "MCD Data:\n",
      "         Date        Open        High         Low       Close  Adj Close  \\\n",
      "0  2014-05-27  102.199997  102.900002  102.070000  102.360001  78.809685   \n",
      "1  2014-05-28  101.839996  102.040001  100.870003  101.300003  77.993576   \n",
      "2  2014-05-29  101.269997  101.489998  100.870003  101.339996  78.653267   \n",
      "3  2014-05-30  101.250000  101.459999  100.709999  101.430000  78.723152   \n",
      "4  2014-06-02  101.389999  102.500000  101.320000  102.029999  79.188812   \n",
      "\n",
      "    Volume  \n",
      "0  5093200  \n",
      "1  8930700  \n",
      "2  4123700  \n",
      "3  4232800  \n",
      "4  3001400  \n",
      "DEO Data:\n",
      "         Date        Open        High         Low       Close  Adj Close  \\\n",
      "0  2014-05-27  127.949997  128.220001  127.510002  127.879997  99.287010   \n",
      "1  2014-05-28  125.690002  126.059998  125.269997  125.660004  97.563400   \n",
      "2  2014-05-29  127.720001  128.130005  127.199997  127.769997  99.201599   \n",
      "3  2014-05-30  128.710007  129.240005  128.380005  128.789993  99.993546   \n",
      "4  2014-06-02  128.309998  128.360001  127.440002  127.919998  99.318054   \n",
      "\n",
      "   Volume  \n",
      "0  212300  \n",
      "1  417300  \n",
      "2  329100  \n",
      "3  318300  \n",
      "4  650900  \n",
      "MSFT Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  40.259998  40.259998  39.810001  40.189999  34.211468  26160600\n",
      "1  2014-05-28  40.139999  40.189999  39.820000  40.009998  34.058243  25711500\n",
      "2  2014-05-29  40.150002  40.349998  39.910000  40.340000  34.339165  19888200\n",
      "3  2014-05-30  40.450001  40.970001  40.250000  40.939999  34.849911  34567600\n",
      "4  2014-06-02  40.950001  41.090000  40.680000  40.790001  34.722214  18504300\n",
      "DE Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  90.279999  91.199997  90.239998  90.919998  75.107590  2829400\n",
      "1  2014-05-28  91.190002  91.540001  90.690002  90.910004  75.099327  1909700\n",
      "2  2014-05-29  90.949997  91.209999  90.330002  91.099998  75.256271  1513100\n",
      "3  2014-05-30  90.860001  91.300003  90.660004  91.169998  75.314117  1768400\n",
      "4  2014-06-02  91.290001  91.680000  91.150002  91.180000  75.322357  1941100\n",
      "NVDA Data:\n",
      "         Date    Open    High     Low   Close  Adj Close    Volume\n",
      "0  2014-05-27  4.6500  4.7050  4.6350  4.7050   4.479233  20968000\n",
      "1  2014-05-28  4.7225  4.7750  4.6775  4.7450   4.517315  22467600\n",
      "2  2014-05-29  4.7425  4.7825  4.7275  4.7375   4.510175  17188400\n",
      "3  2014-05-30  4.7375  4.7625  4.7125  4.7500   4.522075  23912800\n",
      "4  2014-06-02  4.7650  4.7950  4.6950  4.7350   4.507793  18150000\n",
      "CME Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  71.400002  72.029999  71.099998  71.669998  47.923962  1553000\n",
      "1  2014-05-28  71.529999  72.199997  71.320000  71.930000  48.097820  1101700\n",
      "2  2014-05-29  72.019997  72.480003  71.550003  72.459999  48.452194  1003700\n",
      "3  2014-05-30  72.410004  72.470001  71.820000  72.000000  48.144634  1671200\n",
      "4  2014-06-02  72.059998  72.269997  71.010002  71.949997  48.111198  1892500\n",
      "WFC Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  50.299999  50.700001  50.200001  50.549999  37.911568  13322200\n",
      "1  2014-05-28  50.529999  50.700001  50.320000  50.439999  37.829079  12458400\n",
      "2  2014-05-29  50.610001  50.610001  50.150002  50.270000  37.701588  13026600\n",
      "3  2014-05-30  50.320000  50.820000  50.320000  50.779999  38.084057  15489200\n",
      "4  2014-06-02  50.939999  51.169998  50.869999  51.090000  38.316551  11828300\n",
      "GS Data:\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2014-05-27  161.119995  163.429993  160.580002  161.770004  133.732590   \n",
      "1  2014-05-28  160.910004  161.610001  159.779999  161.190002  133.707718   \n",
      "2  2014-05-29  161.139999  162.000000  159.619995  160.740005  133.334412   \n",
      "3  2014-05-30  160.419998  160.639999  159.160004  159.809998  132.563004   \n",
      "4  2014-06-02  159.779999  160.199997  157.910004  160.029999  132.745483   \n",
      "\n",
      "    Volume  \n",
      "0  3248800  \n",
      "1  1855200  \n",
      "2  1779200  \n",
      "3  2206300  \n",
      "4  2162500  \n",
      "DIS Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  83.559998  83.980003  83.320000  83.739998  76.816925  5197700\n",
      "1  2014-05-28  83.800003  83.900002  83.250000  83.599998  76.688492  4652100\n",
      "2  2014-05-29  83.919998  84.089996  83.430000  84.029999  77.082939  6522000\n",
      "3  2014-05-30  83.809998  84.389999  83.620003  84.010002  77.064590  6352400\n",
      "4  2014-06-02  84.269997  84.419998  84.010002  84.269997  77.303101  3933800\n",
      "GOOGL Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  28.389000  28.743500  28.207500  28.743500  28.743500  43716000\n",
      "1  2014-05-28  28.728500  28.882999  28.497499  28.522499  28.522499  31632000\n",
      "2  2014-05-29  28.669500  28.674000  28.422501  28.528000  28.528000  28222000\n",
      "3  2014-05-30  28.582001  28.629000  28.289499  28.582500  28.582500  37434000\n",
      "4  2014-06-02  28.487499  28.520500  27.834999  28.216999  28.216999  33210000\n",
      "META Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  61.619999  63.509998  61.570000  63.480000  63.412716  55682000\n",
      "1  2014-05-28  63.389999  64.139999  62.619999  63.509998  63.442684  47795000\n",
      "2  2014-05-29  63.840000  64.300003  63.509998  63.830002  63.762348  42700000\n",
      "3  2014-05-30  63.950001  64.169998  62.560001  63.299999  63.232906  45253500\n",
      "4  2014-06-02  63.230000  63.590000  62.049999  63.080002  63.013145  35996000\n",
      "GOOG Data:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2014-05-27  27.723885  28.222515  27.641609  28.220022  28.220022  42083223\n",
      "1  2014-05-28  28.151211  28.314262  27.973200  28.007107  28.007107  33040464\n",
      "2  2014-05-29  28.090378  28.122789  27.859013  27.927326  27.927326  27082150\n",
      "3  2014-05-30  27.963226  27.990652  27.719397  27.917852  27.917852  35422988\n",
      "4  2014-06-02  27.958241  27.968212  27.211790  27.620667  27.620667  28700582\n",
      "JCI Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  45.539268  45.832462  45.424084  45.706806  32.157143  1910096\n",
      "1  2014-05-28  45.832462  46.345551  45.748692  45.780106  32.208714  2681258\n",
      "2  2014-05-29  45.790577  45.926701  45.403141  45.759163  32.193962  2683455\n",
      "3  2014-05-30  45.696335  45.874348  45.591621  45.696335  32.149754  3044349\n",
      "4  2014-06-02  45.696335  46.000000  45.319370  45.801048  32.223438  2697684\n",
      "QCOM Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  79.930000  80.500000  79.900002  80.459999  60.045715  8079500\n",
      "1  2014-05-28  80.199997  80.739998  80.160004  80.220001  59.866611  7659100\n",
      "2  2014-05-29  80.580002  80.580002  79.879997  80.190002  59.844238  9704000\n",
      "3  2014-05-30  80.330002  80.529999  79.919998  80.449997  60.038239  7337000\n",
      "4  2014-06-02  80.660004  80.790001  80.040001  80.480003  60.375851  7238400\n",
      "UNH Data:\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2014-05-27  79.230003  79.330002  78.660004  79.110001  67.874077  2645500\n",
      "1  2014-05-28  78.970001  79.209999  78.300003  78.580002  67.419334  2250900\n",
      "2  2014-05-29  78.599998  79.430000  78.080002  79.370003  68.097137  3526800\n",
      "3  2014-05-30  79.239998  79.739998  78.879997  79.629997  68.320198  5139900\n",
      "4  2014-06-02  79.769997  79.930000  79.320000  79.470001  68.182930  1986400\n",
      "AAPL Data:\n",
      "         Date       Open       High        Low      Close  Adj Close  \\\n",
      "0  2014-05-27  21.995714  22.352142  21.986786  22.343929  19.763992   \n",
      "1  2014-05-28  22.357857  22.493929  22.277857  22.286072  19.712812   \n",
      "2  2014-05-29  22.423214  22.745358  22.420357  22.692142  20.071995   \n",
      "3  2014-05-30  22.785000  23.006071  22.460714  22.607143  19.996819   \n",
      "4  2014-06-02  22.641430  22.672501  22.232143  22.451786  19.859396   \n",
      "\n",
      "      Volume  \n",
      "0  348866000  \n",
      "1  315481600  \n",
      "2  376474000  \n",
      "3  564020800  \n",
      "4  369350800  \n",
      "LMT Data:\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2014-05-27  163.130005  163.229996  162.009995  162.949997  123.996162   \n",
      "1  2014-05-28  163.429993  164.600006  161.869995  162.100006  123.349281   \n",
      "2  2014-05-29  161.119995  163.389999  160.580002  163.149994  125.175362   \n",
      "3  2014-05-30  162.729996  163.960007  162.289993  163.649994  125.558937   \n",
      "4  2014-06-02  163.880005  164.410004  162.630005  164.110001  125.911919   \n",
      "\n",
      "    Volume  \n",
      "0  1294500  \n",
      "1  1831500  \n",
      "2  1489200  \n",
      "3  2121200  \n",
      "4  1012600  \n",
      "BRK-B Data:\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2014-05-27  127.410004  127.750000  127.250000  127.519997  127.519997   \n",
      "1  2014-05-28  127.430000  127.940002  127.260002  127.459999  127.459999   \n",
      "2  2014-05-29  127.419998  128.199997  127.099998  128.110001  128.110001   \n",
      "3  2014-05-30  127.669998  128.500000  127.620003  128.339996  128.339996   \n",
      "4  2014-06-02  128.279999  128.750000  127.370003  127.879997  127.879997   \n",
      "\n",
      "    Volume  \n",
      "0  2251600  \n",
      "1  2211300  \n",
      "2  2028900  \n",
      "3  2916700  \n",
      "4  2007200  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = './Dataset/Equities'\n",
    "\n",
    "stock_data = {}\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith('.csv'):\n",
    "        stock_name = file.split('.')[0]\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        stock_data[stock_name] = pd.read_csv(file_path)\n",
    "\n",
    "for stock, data in stock_data.items():\n",
    "    print(f\"{stock} Data:\")\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.098888  0.089476  0.124918  0.113307   0.062498  0.022423\n",
      "2014-05-28  0.101998  0.092221  0.128620  0.113770   0.062911  0.017774\n",
      "2014-05-29  0.103554  0.092367  0.129360  0.116114   0.064999  0.014110\n",
      "2014-05-30  0.103438  0.093067  0.128250  0.116432   0.065282  0.019247\n",
      "2014-06-02  0.105828  0.094790  0.130328  0.118313   0.066958  0.017974\n",
      "MSBHF Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close  Volume\n",
      "Date                                                                 \n",
      "2014-05-27  0.090584  0.089442  0.093794  0.093695   0.056429     0.0\n",
      "2014-05-28  0.090584  0.089442  0.093794  0.093695   0.056429     0.0\n",
      "2014-05-29  0.090584  0.089442  0.093794  0.093695   0.056429     0.0\n",
      "2014-05-30  0.090584  0.089442  0.093794  0.093695   0.056429     0.0\n",
      "2014-06-02  0.090584  0.089442  0.093794  0.093695   0.056429     0.0\n",
      "V Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.016512  0.013048  0.018434  0.014825   0.013301  0.163276\n",
      "2014-05-28  0.018081  0.013027  0.018632  0.014097   0.012630  0.113423\n",
      "2014-05-29  0.017561  0.013224  0.019145  0.015002   0.013464  0.073542\n",
      "2014-05-30  0.019514  0.014534  0.018967  0.015168   0.013618  0.091341\n",
      "2014-06-02  0.018984  0.014264  0.018454  0.013805   0.012361  0.095965\n",
      "HCA Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.002700  0.002548  0.031796  0.000463   0.000432  0.020308\n",
      "2014-05-28  0.001208  0.002442  0.032319  0.001355   0.001262  0.023852\n",
      "2014-05-29  0.001172  0.001345  0.032702  0.001426   0.001328  0.017908\n",
      "2014-05-30  0.000924  0.000849  0.031238  0.000000   0.000000  0.028678\n",
      "2014-06-02  0.000213  0.000000  0.029495  0.000000   0.000000  0.046054\n",
      "NTDOY Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.033626  0.033451  0.035699  0.035013   0.035013  0.033472\n",
      "2014-05-28  0.032763  0.032459  0.034552  0.033874   0.033874  0.036078\n",
      "2014-05-29  0.035350  0.036428  0.037563  0.037717   0.037717  0.004061\n",
      "2014-05-30  0.038224  0.037137  0.038136  0.038002   0.038002  0.000194\n",
      "2014-06-02  0.037074  0.036712  0.038280  0.037432   0.037432  0.002127\n",
      "ADM Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.196087  0.196818  0.216399  0.217820   0.138490  0.042328\n",
      "2014-05-28  0.205869  0.199617  0.225085  0.217385   0.138164  0.030645\n",
      "2014-05-29  0.206892  0.201679  0.227146  0.222464   0.141965  0.028004\n",
      "2014-05-30  0.209374  0.205952  0.230237  0.226818   0.145224  0.034049\n",
      "2014-06-02  0.214192  0.206983  0.233181  0.225512   0.144246  0.040094\n",
      "LH Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.019794  0.013339  0.022249  0.014233   0.014233  0.040916\n",
      "2014-05-28  0.020717  0.012562  0.019537  0.012985   0.012985  0.039410\n",
      "2014-05-29  0.020579  0.021242  0.022754  0.023521   0.023521  0.087247\n",
      "2014-05-30  0.028515  0.020237  0.029466  0.022043   0.022042  0.065797\n",
      "2014-06-02  0.028653  0.020511  0.028960  0.019778   0.019778  0.043146\n",
      "BAC Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.092068  0.097510  0.104890  0.106227   0.085112  0.308881\n",
      "2014-05-28  0.099090  0.096732  0.106204  0.104134   0.083343  0.162411\n",
      "2014-05-29  0.095189  0.094917  0.108044  0.104396   0.083564  0.070907\n",
      "2014-05-30  0.095189  0.095436  0.107256  0.104134   0.083343  0.088522\n",
      "2014-06-02  0.096229  0.096732  0.106730  0.107274   0.085997  0.090147\n",
      "IRM Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.107091  0.100887  0.112239  0.109486   0.003704  0.057574\n",
      "2014-05-28  0.112209  0.108626  0.117845  0.113856   0.005802  0.092017\n",
      "2014-05-29  0.116124  0.108930  0.120118  0.117171   0.007394  0.042072\n",
      "2014-05-30  0.119586  0.109840  0.123754  0.118377   0.007973  0.055888\n",
      "2014-06-02  0.121845  0.111510  0.123451  0.118527   0.008046  0.051201\n",
      "STZ Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.008429  0.005521  0.012501  0.007183   0.006116  0.055645\n",
      "2014-05-28  0.010366  0.005885  0.010295  0.005610   0.004777  0.056337\n",
      "2014-05-29  0.008795  0.006458  0.013026  0.008914   0.007589  0.032462\n",
      "2014-05-30  0.011151  0.007604  0.015547  0.010749   0.009152  0.047129\n",
      "2014-06-02  0.011937  0.006302  0.012921  0.009753   0.008303  0.034485\n",
      "ULTA Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.001845  0.005068  0.004710  0.004810   0.004810  0.043699\n",
      "2014-05-28  0.004306  0.003637  0.000461  0.001037   0.001037  0.053111\n",
      "2014-05-29  0.001640  0.000756  0.000000  0.000270   0.000270  0.054730\n",
      "2014-05-30  0.000000  0.000000  0.001717  0.000000   0.000000  0.028987\n",
      "2014-06-02  0.000308  0.003842  0.002512  0.003940   0.003940  0.032384\n",
      "ARE Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.019742  0.018368  0.023459  0.021064   0.003669  0.030331\n",
      "2014-05-28  0.016771  0.015875  0.022933  0.021130   0.003717  0.022025\n",
      "2014-05-29  0.018290  0.019811  0.026416  0.025145   0.006668  0.005755\n",
      "2014-05-30  0.021129  0.024731  0.030096  0.029226   0.009668  0.026129\n",
      "2014-06-02  0.024232  0.029979  0.033644  0.034492   0.013538  0.015511\n",
      "PEP Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.000000  0.000000  0.077404  0.000000   0.000000  0.131832\n",
      "2014-05-28  0.004875  0.004807  0.083228  0.004927   0.003223  0.117984\n",
      "2014-05-29  0.010654  0.010975  0.087786  0.010950   0.007161  0.141098\n",
      "2014-05-30  0.016251  0.016780  0.092260  0.016425   0.010742  0.161127\n",
      "2014-06-02  0.020856  0.015964  0.095214  0.012227   0.007997  0.074703\n",
      "MDLZ Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.112597  0.110028  0.118057  0.115218   0.082355  0.178513\n",
      "2014-05-28  0.115833  0.110028  0.118275  0.114570   0.081867  0.183082\n",
      "2014-05-29  0.117343  0.109812  0.119800  0.116299   0.083167  0.154808\n",
      "2014-05-30  0.120362  0.113710  0.119582  0.119326   0.085441  0.352090\n",
      "2014-06-02  0.118637  0.119125  0.122196  0.122568   0.087879  0.129019\n",
      "DLR Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.008657  0.008812  0.011154  0.007653   0.000997  0.018189\n",
      "2014-05-28  0.007242  0.009883  0.010571  0.008152   0.001329  0.019266\n",
      "2014-05-29  0.003746  0.006671  0.004578  0.006156   0.000000  0.030240\n",
      "2014-05-30  0.006160  0.009636  0.010987  0.006988   0.000554  0.030540\n",
      "2014-06-02  0.006743  0.011118  0.012569  0.011979   0.003876  0.015330\n",
      "LVMUY Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.060679  0.060034  0.062577  0.059948   0.033575  0.018250\n",
      "2014-05-28  0.058510  0.058285  0.060585  0.058717   0.032664  0.009887\n",
      "2014-05-29  0.059155  0.059276  0.061288  0.059596   0.033315  0.025088\n",
      "2014-05-30  0.061617  0.062715  0.063339  0.063527   0.036221  0.017205\n",
      "2014-06-02  0.060562  0.059976  0.061932  0.060300   0.033835  0.011760\n",
      "MRK Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.092094  0.087742  0.117581  0.092028   0.043477  0.053009\n",
      "2014-05-28  0.089668  0.084312  0.116817  0.088801   0.041363  0.048209\n",
      "2014-05-29  0.091874  0.096040  0.118998  0.103268   0.050839  0.065690\n",
      "2014-05-30  0.098602  0.101351  0.129033  0.105048   0.052005  0.097137\n",
      "2014-06-02  0.102903  0.100577  0.128597  0.105827   0.052516  0.043839\n",
      "ORCL Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.087469  0.082403  0.089752  0.083631   0.061687  0.124386\n",
      "2014-05-28  0.084677  0.080779  0.087977  0.080063   0.058751  0.108159\n",
      "2014-05-29  0.082610  0.080982  0.088499  0.086674   0.064191  0.088288\n",
      "2014-05-30  0.085608  0.080881  0.091004  0.084785   0.062636  0.134045\n",
      "2014-06-02  0.084367  0.079054  0.088499  0.084260   0.062205  0.107876\n",
      "SBUX Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.008067  0.005062  0.009897  0.008170   0.005764  0.127428\n",
      "2014-05-28  0.011714  0.003894  0.012021  0.006002   0.003932  0.098238\n",
      "2014-05-29  0.012930  0.003838  0.010512  0.005113   0.003181  0.071031\n",
      "2014-05-30  0.010940  0.003504  0.009841  0.005836   0.003791  0.077690\n",
      "2014-06-02  0.011272  0.006620  0.013363  0.009226   0.006657  0.062974\n",
      "IPGP Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.006169  0.005661  0.009821  0.007249   0.007249  0.039299\n",
      "2014-05-28  0.009476  0.004519  0.010171  0.005163   0.005163  0.045467\n",
      "2014-05-29  0.007897  0.003774  0.009670  0.005263   0.005263  0.029417\n",
      "2014-05-30  0.006811  0.003675  0.008819  0.005858   0.005858  0.020302\n",
      "2014-06-02  0.009081  0.003526  0.009420  0.006057   0.006057  0.019830\n",
      "PG Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.125313  0.122506  0.146477  0.119852   0.060908  0.040930\n",
      "2014-05-28  0.120112  0.119513  0.146185  0.120052   0.061038  0.017905\n",
      "2014-05-29  0.120812  0.120710  0.146769  0.123043   0.062998  0.015320\n",
      "2014-05-30  0.122312  0.125199  0.147646  0.126932   0.065546  0.044456\n",
      "2014-06-02  0.126413  0.123404  0.148816  0.122644   0.062737  0.018976\n",
      "MCD Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.066375  0.061533  0.068788  0.065544   0.039080  0.169795\n",
      "2014-05-28  0.064684  0.057487  0.063123  0.060546   0.035516  0.327565\n",
      "2014-05-29  0.062007  0.054900  0.063123  0.060735   0.038397  0.129937\n",
      "2014-05-30  0.061913  0.054758  0.062367  0.061159   0.038703  0.134422\n",
      "2014-06-02  0.062570  0.059651  0.065247  0.063988   0.040736  0.083796\n",
      "DEO Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.229282  0.226532  0.230144  0.228635   0.129761  0.031882\n",
      "2014-05-28  0.210682  0.208931  0.211766  0.210462   0.116246  0.083630\n",
      "2014-05-29  0.227389  0.225799  0.227601  0.227734   0.129091  0.061366\n",
      "2014-05-30  0.235536  0.234844  0.237283  0.236084   0.135301  0.058639\n",
      "2014-06-02  0.232244  0.227673  0.229570  0.228962   0.130004  0.142598\n",
      "MSFT Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.000305  0.000178  0.000232  0.000461   0.000386  0.096029\n",
      "2014-05-28  0.000000  0.000000  0.000258  0.000000   0.000000  0.093727\n",
      "2014-05-29  0.000025  0.000407  0.000490  0.000845   0.000709  0.063879\n",
      "2014-05-30  0.000789  0.001983  0.001368  0.002382   0.001997  0.139121\n",
      "2014-06-02  0.002062  0.002288  0.002478  0.001997   0.001675  0.056786\n",
      "DE Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.050654  0.048251  0.054223  0.051101   0.033767  0.108314\n",
      "2014-05-28  0.053091  0.049152  0.055439  0.051075   0.033746  0.069087\n",
      "2014-05-29  0.052448  0.048277  0.054466  0.051582   0.034159  0.052172\n",
      "2014-05-30  0.052207  0.048516  0.055358  0.051769   0.034312  0.063061\n",
      "2014-06-02  0.053359  0.049524  0.056681  0.051795   0.034334  0.070427\n",
      "NVDA Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.000401  0.000358  0.000431  0.000479   0.000439  0.044975\n",
      "2014-05-28  0.000471  0.000424  0.000473  0.000516   0.000475  0.049086\n",
      "2014-05-29  0.000490  0.000431  0.000522  0.000509   0.000468  0.034612\n",
      "2014-05-30  0.000485  0.000413  0.000507  0.000521   0.000479  0.053049\n",
      "2014-06-02  0.000512  0.000443  0.000490  0.000507   0.000466  0.037249\n",
      "CME Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.011573  0.010965  0.010833  0.011917   0.007952  0.166999\n",
      "2014-05-28  0.012289  0.011874  0.012062  0.013352   0.008910  0.106258\n",
      "2014-05-29  0.014989  0.013372  0.013346  0.016276   0.010861  0.093069\n",
      "2014-05-30  0.017139  0.013318  0.014854  0.013738   0.009167  0.182907\n",
      "2014-06-02  0.015210  0.012249  0.010331  0.013462   0.008983  0.212692\n",
      "WFC Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.652319  0.652571  0.655679  0.656620   0.430841  0.078716\n",
      "2014-05-28  0.657449  0.652571  0.658352  0.654164   0.428919  0.071182\n",
      "2014-05-29  0.659233  0.650568  0.654566  0.650368   0.425949  0.076138\n",
      "2014-05-30  0.652765  0.655242  0.658352  0.661755   0.434860  0.097616\n",
      "2014-06-02  0.666592  0.663031  0.670601  0.668676   0.440277  0.065686\n",
      "GS Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.075534  0.067222  0.089172  0.079895   0.041957  0.189268\n",
      "2014-05-28  0.074901  0.061711  0.086773  0.078166   0.041886  0.094685\n",
      "2014-05-29  0.075594  0.062892  0.086293  0.076824   0.040824  0.089527\n",
      "2014-05-30  0.073426  0.058774  0.084913  0.074052   0.038628  0.118514\n",
      "2014-06-02  0.071500  0.057441  0.081164  0.074708   0.039148  0.115541\n",
      "DIS Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.036832  0.034001  0.040904  0.036055   0.014529  0.035568\n",
      "2014-05-28  0.038814  0.033352  0.040305  0.034913   0.013512  0.029168\n",
      "2014-05-29  0.039805  0.034894  0.041845  0.038421   0.016636  0.051103\n",
      "2014-05-30  0.038897  0.037329  0.043471  0.038258   0.016491  0.049114\n",
      "2014-06-02  0.042696  0.037572  0.046808  0.040378   0.018380  0.020741\n",
      "GOOGL Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.022530  0.024256  0.024166  0.025429   0.025429  0.138810\n",
      "2014-05-28  0.024762  0.025163  0.026080  0.023984   0.023984  0.090054\n",
      "2014-05-29  0.024374  0.023804  0.025585  0.024020   0.024020  0.076296\n",
      "2014-05-30  0.023799  0.023511  0.024707  0.024376   0.024376  0.113464\n",
      "2014-06-02  0.023178  0.022806  0.021708  0.021987   0.021987  0.096421\n",
      "META Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.000000  0.000363  0.000000  0.002108   0.002106  0.221356\n",
      "2014-05-28  0.003785  0.001709  0.002296  0.002173   0.002170  0.186589\n",
      "2014-05-29  0.004747  0.002051  0.004242  0.002861   0.002858  0.164129\n",
      "2014-05-30  0.004982  0.001773  0.002165  0.001721   0.001719  0.175385\n",
      "2014-06-02  0.003443  0.000534  0.001050  0.001248   0.001246  0.134576\n",
      "GOOG Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.019849  0.022495  0.021767  0.023616   0.023616  0.162446\n",
      "2014-05-28  0.022622  0.023086  0.023934  0.022242   0.022242  0.120652\n",
      "2014-05-29  0.022227  0.021852  0.023188  0.021727   0.021727  0.093113\n",
      "2014-05-30  0.021402  0.021001  0.022276  0.021666   0.021666  0.131664\n",
      "2014-06-02  0.021370  0.020856  0.018958  0.019748   0.019748  0.100593\n",
      "JCI Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.371597  0.371941  0.389408  0.384134   0.193452  0.039529\n",
      "2014-05-28  0.376760  0.380908  0.394990  0.385402   0.194382  0.068082\n",
      "2014-05-29  0.376023  0.373588  0.389048  0.385040   0.194116  0.068163\n",
      "2014-05-30  0.374363  0.372673  0.392289  0.383953   0.193319  0.081526\n",
      "2014-06-02  0.374363  0.374869  0.387607  0.385765   0.194648  0.068690\n",
      "QCOM Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.229051  0.221475  0.233449  0.224014   0.149516  0.038722\n",
      "2014-05-28  0.230703  0.222903  0.235061  0.222581   0.148502  0.035990\n",
      "2014-05-29  0.233029  0.221951  0.233325  0.222401   0.148376  0.049278\n",
      "2014-05-30  0.231499  0.221653  0.233573  0.223955   0.149474  0.033898\n",
      "2014-06-02  0.233519  0.223201  0.234317  0.224134   0.151384  0.033257\n",
      "UNH Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.002788  0.002251  0.002391  0.002326   0.001324  0.072484\n",
      "2014-05-28  0.002243  0.002001  0.001629  0.001216   0.000380  0.057675\n",
      "2014-05-29  0.001467  0.002459  0.001164  0.002871   0.001787  0.105556\n",
      "2014-05-30  0.002809  0.003105  0.002857  0.003416   0.002250  0.166091\n",
      "2014-06-02  0.003920  0.003501  0.003788  0.003081   0.001965  0.047749\n",
      "AAPL Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.000000  0.000000  0.000000  0.000329   0.000288  0.441726\n",
      "2014-05-28  0.002057  0.000800  0.001663  0.000000   0.000000  0.396326\n",
      "2014-05-29  0.002429  0.002218  0.002477  0.002310   0.002019  0.479271\n",
      "2014-05-30  0.004484  0.003689  0.002708  0.001826   0.001597  0.734320\n",
      "2014-06-02  0.003668  0.001807  0.001402  0.000942   0.000824  0.469584\n",
      "LMT Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.019955  0.013699  0.016912  0.016676   0.009204  0.071371\n",
      "2014-05-28  0.020823  0.017617  0.016502  0.014207   0.007441  0.110736\n",
      "2014-05-29  0.014142  0.014157  0.012728  0.017257   0.012416  0.085644\n",
      "2014-05-30  0.018799  0.015787  0.017731  0.018710   0.013461  0.131973\n",
      "2014-06-02  0.022125  0.017074  0.018726  0.020046   0.014423  0.050706\n",
      "BRK-B Preprocessed Data:\n",
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2014-05-27  0.011010  0.006280  0.015314  0.011438   0.011438  0.098279\n",
      "2014-05-28  0.011077  0.006904  0.015348  0.011235   0.011235  0.096465\n",
      "2014-05-29  0.011043  0.007759  0.014807  0.013428   0.013428  0.088259\n",
      "2014-05-30  0.011877  0.008745  0.016565  0.014204   0.014204  0.128202\n",
      "2014-06-02  0.013913  0.009567  0.015720  0.012652   0.012652  0.087283\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.dropna()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "    return scaled_df, scaler\n",
    "\n",
    "preprocessed_data = {}\n",
    "scalers = {}\n",
    "for stock, data in stock_data.items():\n",
    "    preprocessed_data[stock], scalers[stock] = preprocess_data(data)\n",
    "\n",
    "for stock, data in preprocessed_data.items():\n",
    "    print(f\"{stock} Preprocessed Data:\")\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for BA...\n",
      "Epoch [2/10], Loss: 0.1126\n",
      "Epoch [4/10], Loss: 0.0924\n",
      "Epoch [6/10], Loss: 0.0755\n",
      "Epoch [8/10], Loss: 0.0612\n",
      "Epoch [10/10], Loss: 0.0501\n",
      "Training model for MSBHF...\n",
      "Epoch [2/10], Loss: 0.0756\n",
      "Epoch [4/10], Loss: 0.0579\n",
      "Epoch [6/10], Loss: 0.0428\n",
      "Epoch [8/10], Loss: 0.0306\n",
      "Epoch [10/10], Loss: 0.0225\n",
      "Training model for V...\n",
      "Epoch [2/10], Loss: 0.2574\n",
      "Epoch [4/10], Loss: 0.2124\n",
      "Epoch [6/10], Loss: 0.1698\n",
      "Epoch [8/10], Loss: 0.1288\n",
      "Epoch [10/10], Loss: 0.0903\n",
      "Training model for HCA...\n",
      "Epoch [2/10], Loss: 0.2845\n",
      "Epoch [4/10], Loss: 0.2428\n",
      "Epoch [6/10], Loss: 0.2023\n",
      "Epoch [8/10], Loss: 0.1613\n",
      "Epoch [10/10], Loss: 0.1185\n",
      "Training model for NTDOY...\n",
      "Epoch [2/10], Loss: 0.2500\n",
      "Epoch [4/10], Loss: 0.2131\n",
      "Epoch [6/10], Loss: 0.1773\n",
      "Epoch [8/10], Loss: 0.1415\n",
      "Epoch [10/10], Loss: 0.1057\n",
      "Training model for ADM...\n",
      "Epoch [2/10], Loss: 0.2358\n",
      "Epoch [4/10], Loss: 0.1978\n",
      "Epoch [6/10], Loss: 0.1591\n",
      "Epoch [8/10], Loss: 0.1187\n",
      "Epoch [10/10], Loss: 0.0769\n",
      "Training model for LH...\n",
      "Epoch [2/10], Loss: 0.2807\n",
      "Epoch [4/10], Loss: 0.2434\n",
      "Epoch [6/10], Loss: 0.2071\n",
      "Epoch [8/10], Loss: 0.1705\n",
      "Epoch [10/10], Loss: 0.1326\n",
      "Training model for BAC...\n",
      "Epoch [2/10], Loss: 0.2068\n",
      "Epoch [4/10], Loss: 0.1702\n",
      "Epoch [6/10], Loss: 0.1369\n",
      "Epoch [8/10], Loss: 0.1056\n",
      "Epoch [10/10], Loss: 0.0761\n",
      "Training model for IRM...\n",
      "Epoch [2/10], Loss: 0.0874\n",
      "Epoch [4/10], Loss: 0.0680\n",
      "Epoch [6/10], Loss: 0.0521\n",
      "Epoch [8/10], Loss: 0.0402\n",
      "Epoch [10/10], Loss: 0.0340\n",
      "Training model for STZ...\n",
      "Epoch [2/10], Loss: 0.2205\n",
      "Epoch [4/10], Loss: 0.1715\n",
      "Epoch [6/10], Loss: 0.1254\n",
      "Epoch [8/10], Loss: 0.0827\n",
      "Epoch [10/10], Loss: 0.0470\n",
      "Training model for ULTA...\n",
      "Epoch [2/10], Loss: 0.3333\n",
      "Epoch [4/10], Loss: 0.2809\n",
      "Epoch [6/10], Loss: 0.2326\n",
      "Epoch [8/10], Loss: 0.1862\n",
      "Epoch [10/10], Loss: 0.1402\n",
      "Training model for ARE...\n",
      "Epoch [2/10], Loss: 0.2002\n",
      "Epoch [4/10], Loss: 0.1681\n",
      "Epoch [6/10], Loss: 0.1388\n",
      "Epoch [8/10], Loss: 0.1111\n",
      "Epoch [10/10], Loss: 0.0839\n",
      "Training model for PEP...\n",
      "Epoch [2/10], Loss: 0.4122\n",
      "Epoch [4/10], Loss: 0.3655\n",
      "Epoch [6/10], Loss: 0.3221\n",
      "Epoch [8/10], Loss: 0.2797\n",
      "Epoch [10/10], Loss: 0.2366\n",
      "Training model for MDLZ...\n",
      "Epoch [2/10], Loss: 0.2370\n",
      "Epoch [4/10], Loss: 0.1936\n",
      "Epoch [6/10], Loss: 0.1501\n",
      "Epoch [8/10], Loss: 0.1063\n",
      "Epoch [10/10], Loss: 0.0647\n",
      "Training model for DLR...\n",
      "Epoch [2/10], Loss: 0.3486\n",
      "Epoch [4/10], Loss: 0.3014\n",
      "Epoch [6/10], Loss: 0.2543\n",
      "Epoch [8/10], Loss: 0.2059\n",
      "Epoch [10/10], Loss: 0.1550\n",
      "Training model for LVMUY...\n",
      "Epoch [2/10], Loss: 0.1536\n",
      "Epoch [4/10], Loss: 0.1251\n",
      "Epoch [6/10], Loss: 0.0989\n",
      "Epoch [8/10], Loss: 0.0757\n",
      "Epoch [10/10], Loss: 0.0574\n",
      "Training model for MRK...\n",
      "Epoch [2/10], Loss: 0.0906\n",
      "Epoch [4/10], Loss: 0.0751\n",
      "Epoch [6/10], Loss: 0.0612\n",
      "Epoch [8/10], Loss: 0.0492\n",
      "Epoch [10/10], Loss: 0.0401\n",
      "Training model for ORCL...\n",
      "Epoch [2/10], Loss: 0.1561\n",
      "Epoch [4/10], Loss: 0.1290\n",
      "Epoch [6/10], Loss: 0.1048\n",
      "Epoch [8/10], Loss: 0.0827\n",
      "Epoch [10/10], Loss: 0.0628\n",
      "Training model for SBUX...\n",
      "Epoch [2/10], Loss: 0.2199\n",
      "Epoch [4/10], Loss: 0.1804\n",
      "Epoch [6/10], Loss: 0.1426\n",
      "Epoch [8/10], Loss: 0.1056\n",
      "Epoch [10/10], Loss: 0.0704\n",
      "Training model for IPGP...\n",
      "Epoch [2/10], Loss: 0.1626\n",
      "Epoch [4/10], Loss: 0.1344\n",
      "Epoch [6/10], Loss: 0.1095\n",
      "Epoch [8/10], Loss: 0.0870\n",
      "Epoch [10/10], Loss: 0.0665\n",
      "Training model for PG...\n",
      "Epoch [2/10], Loss: 0.3699\n",
      "Epoch [4/10], Loss: 0.3246\n",
      "Epoch [6/10], Loss: 0.2810\n",
      "Epoch [8/10], Loss: 0.2368\n",
      "Epoch [10/10], Loss: 0.1902\n",
      "Training model for MCD...\n",
      "Epoch [2/10], Loss: 0.2654\n",
      "Epoch [4/10], Loss: 0.2227\n",
      "Epoch [6/10], Loss: 0.1831\n",
      "Epoch [8/10], Loss: 0.1458\n",
      "Epoch [10/10], Loss: 0.1105\n",
      "Training model for DEO...\n",
      "Epoch [2/10], Loss: 0.1321\n",
      "Epoch [4/10], Loss: 0.1054\n",
      "Epoch [6/10], Loss: 0.0804\n",
      "Epoch [8/10], Loss: 0.0573\n",
      "Epoch [10/10], Loss: 0.0383\n",
      "Training model for MSFT...\n",
      "Epoch [2/10], Loss: 0.1973\n",
      "Epoch [4/10], Loss: 0.1684\n",
      "Epoch [6/10], Loss: 0.1421\n",
      "Epoch [8/10], Loss: 0.1173\n",
      "Epoch [10/10], Loss: 0.0934\n",
      "Training model for DE...\n",
      "Epoch [2/10], Loss: 0.1905\n",
      "Epoch [4/10], Loss: 0.1586\n",
      "Epoch [6/10], Loss: 0.1298\n",
      "Epoch [8/10], Loss: 0.1033\n",
      "Epoch [10/10], Loss: 0.0797\n",
      "Training model for NVDA...\n",
      "Epoch [2/10], Loss: 0.0397\n",
      "Epoch [4/10], Loss: 0.0323\n",
      "Epoch [6/10], Loss: 0.0274\n",
      "Epoch [8/10], Loss: 0.0252\n",
      "Epoch [10/10], Loss: 0.0247\n",
      "Training model for CME...\n",
      "Epoch [2/10], Loss: 0.3852\n",
      "Epoch [4/10], Loss: 0.3363\n",
      "Epoch [6/10], Loss: 0.2870\n",
      "Epoch [8/10], Loss: 0.2356\n",
      "Epoch [10/10], Loss: 0.1804\n",
      "Training model for WFC...\n",
      "Epoch [2/10], Loss: 0.3187\n",
      "Epoch [4/10], Loss: 0.2666\n",
      "Epoch [6/10], Loss: 0.2159\n",
      "Epoch [8/10], Loss: 0.1652\n",
      "Epoch [10/10], Loss: 0.1140\n",
      "Training model for GS...\n",
      "Epoch [2/10], Loss: 0.1654\n",
      "Epoch [4/10], Loss: 0.1343\n",
      "Epoch [6/10], Loss: 0.1052\n",
      "Epoch [8/10], Loss: 0.0777\n",
      "Epoch [10/10], Loss: 0.0532\n",
      "Training model for DIS...\n",
      "Epoch [2/10], Loss: 0.0639\n",
      "Epoch [4/10], Loss: 0.0519\n",
      "Epoch [6/10], Loss: 0.0437\n",
      "Epoch [8/10], Loss: 0.0394\n",
      "Epoch [10/10], Loss: 0.0384\n",
      "Training model for GOOGL...\n",
      "Epoch [2/10], Loss: 0.0799\n",
      "Epoch [4/10], Loss: 0.0645\n",
      "Epoch [6/10], Loss: 0.0537\n",
      "Epoch [8/10], Loss: 0.0470\n",
      "Epoch [10/10], Loss: 0.0441\n",
      "Training model for META...\n",
      "Epoch [2/10], Loss: 0.0533\n",
      "Epoch [4/10], Loss: 0.0433\n",
      "Epoch [6/10], Loss: 0.0369\n",
      "Epoch [8/10], Loss: 0.0338\n",
      "Epoch [10/10], Loss: 0.0330\n",
      "Training model for GOOG...\n",
      "Epoch [2/10], Loss: 0.0837\n",
      "Epoch [4/10], Loss: 0.0703\n",
      "Epoch [6/10], Loss: 0.0590\n",
      "Epoch [8/10], Loss: 0.0509\n",
      "Epoch [10/10], Loss: 0.0470\n",
      "Training model for JCI...\n",
      "Epoch [2/10], Loss: 0.1757\n",
      "Epoch [4/10], Loss: 0.1470\n",
      "Epoch [6/10], Loss: 0.1209\n",
      "Epoch [8/10], Loss: 0.0965\n",
      "Epoch [10/10], Loss: 0.0733\n",
      "Training model for QCOM...\n",
      "Epoch [2/10], Loss: 0.1111\n",
      "Epoch [4/10], Loss: 0.0907\n",
      "Epoch [6/10], Loss: 0.0735\n",
      "Epoch [8/10], Loss: 0.0589\n",
      "Epoch [10/10], Loss: 0.0470\n",
      "Training model for UNH...\n",
      "Epoch [2/10], Loss: 0.2459\n",
      "Epoch [4/10], Loss: 0.2072\n",
      "Epoch [6/10], Loss: 0.1704\n",
      "Epoch [8/10], Loss: 0.1345\n",
      "Epoch [10/10], Loss: 0.0992\n",
      "Training model for AAPL...\n",
      "Epoch [2/10], Loss: 0.2560\n",
      "Epoch [4/10], Loss: 0.2158\n",
      "Epoch [6/10], Loss: 0.1785\n",
      "Epoch [8/10], Loss: 0.1429\n",
      "Epoch [10/10], Loss: 0.1092\n",
      "Training model for LMT...\n",
      "Epoch [2/10], Loss: 0.2962\n",
      "Epoch [4/10], Loss: 0.2544\n",
      "Epoch [6/10], Loss: 0.2140\n",
      "Epoch [8/10], Loss: 0.1736\n",
      "Epoch [10/10], Loss: 0.1320\n",
      "Training model for BRK-B...\n",
      "Epoch [2/10], Loss: 0.2558\n",
      "Epoch [4/10], Loss: 0.2154\n",
      "Epoch [6/10], Loss: 0.1766\n",
      "Epoch [8/10], Loss: 0.1380\n",
      "Epoch [10/10], Loss: 0.0993\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexes/base.py:6456\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   6455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6456\u001b[0m     slc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexes/range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2014-08-20 00:00:00')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m next_day_values \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stock, allocation \u001b[38;5;129;01min\u001b[39;00m allocations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# Ensure that the date slicing and indexing works correctly\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     next_day_close_price \u001b[38;5;241m=\u001b[39m \u001b[43mstock_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstock\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     87\u001b[0m     next_day_value \u001b[38;5;241m=\u001b[39m next_day_close_price \u001b[38;5;241m*\u001b[39m allocation \u001b[38;5;241m*\u001b[39m current_investment\n\u001b[1;32m     88\u001b[0m     next_day_values[stock] \u001b[38;5;241m=\u001b[39m next_day_value\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexing.py:1323\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexing.py:1355\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1354\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m-> 1355\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexes/base.py:6344\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[0;34m(self, start, end, step)\u001b[0m\n\u001b[1;32m   6300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_indexer\u001b[39m(\n\u001b[1;32m   6301\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6302\u001b[0m     start: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   6303\u001b[0m     end: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   6304\u001b[0m     step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   6305\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mslice\u001b[39m:\n\u001b[1;32m   6306\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6307\u001b[0m \u001b[38;5;124;03m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[1;32m   6308\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6342\u001b[0m \u001b[38;5;124;03m    slice(1, 3, None)\u001b[39;00m\n\u001b[1;32m   6343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6344\u001b[0m     start_slice, end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6346\u001b[0m     \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[1;32m   6347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexes/base.py:6537\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[0;34m(self, start, end, step)\u001b[0m\n\u001b[1;32m   6535\u001b[0m start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 6537\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6539\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexes/base.py:6459\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   6457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   6458\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6459\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_searchsorted_monotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6460\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   6461\u001b[0m         \u001b[38;5;66;03m# raise the original KeyError\u001b[39;00m\n\u001b[1;32m   6462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/indexes/base.py:6412\u001b[0m, in \u001b[0;36mIndex._searchsorted_monotonic\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   6410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_searchsorted_monotonic\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, side: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   6411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_monotonic_increasing:\n\u001b[0;32m-> 6412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6413\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_monotonic_decreasing:\n\u001b[1;32m   6414\u001b[0m         \u001b[38;5;66;03m# np.searchsorted expects ascending sort order, have to reverse\u001b[39;00m\n\u001b[1;32m   6415\u001b[0m         \u001b[38;5;66;03m# everything for it to work (element ordering, search side and\u001b[39;00m\n\u001b[1;32m   6416\u001b[0m         \u001b[38;5;66;03m# resulting value).\u001b[39;00m\n\u001b[1;32m   6417\u001b[0m         pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msearchsorted(\n\u001b[1;32m   6418\u001b[0m             label, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6419\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/base.py:1323\u001b[0m, in \u001b[0;36mIndexOpsMixin.searchsorted\u001b[0;34m(self, value, side, sorter)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;66;03m# Going through EA.searchsorted directly improves performance GH#38083\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39msearchsorted(value, side\u001b[38;5;241m=\u001b[39mside, sorter\u001b[38;5;241m=\u001b[39msorter)\n\u001b[0;32m-> 1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43msorter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/pandas/core/algorithms.py:1348\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(arr, value, side, sorter)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     arr \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(arr)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;66;03m# Argument 1 to \"searchsorted\" of \"ndarray\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;66;03m# \"Union[NumpyValueArrayLike, ExtensionArray]\"; expected \"NumpyValueArrayLike\"\u001b[39;00m\n\u001b[0;32m-> 1348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = {}, {}, {}, {}\n",
    "for stock in X:\n",
    "    X_train[stock], X_test[stock], y_train[stock], y_test[stock] = train_test_split(X[stock], y[stock], test_size=0.2, random_state=42)\n",
    "\n",
    "def to_tensor(data):\n",
    "    return torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "X_train_tensors = {stock: to_tensor(X_train[stock]) for stock in X_train}\n",
    "X_test_tensors = {stock: to_tensor(X_test[stock]) for stock in X_test}\n",
    "y_train_tensors = {stock: to_tensor(y_train[stock]) for stock in y_train}\n",
    "y_test_tensors = {stock: to_tensor(y_test[stock]) for stock in y_test}\n",
    "\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(StockLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        c_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = X_train_tensors[next(iter(X_train_tensors))].shape[2]\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "models = {}\n",
    "for stock in X_train_tensors:\n",
    "    print(f\"Training model for {stock}...\")\n",
    "    model = StockLSTM(input_size, hidden_size, num_layers)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(X_train_tensors[stock].to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, y_train_tensors[stock].to(device).view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 2 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    models[stock] = model\n",
    "\n",
    "def predict_next_day_return(model, data):\n",
    "    model.eval()\n",
    "    last_sequence = data[-seq_length:]\n",
    "    last_sequence = torch.tensor(last_sequence.values, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(last_sequence)\n",
    "    return prediction.item()\n",
    "\n",
    "initial_investment = 10000  # Starting with $10,000\n",
    "daily_portfolio_value = []\n",
    "\n",
    "current_investment = initial_investment\n",
    "investment_dates = preprocessed_data[next(iter(preprocessed_data))].index[seq_length:]  # Dates for investment\n",
    "for date in investment_dates:\n",
    "    predicted_returns = {}\n",
    "    for stock, model in models.items():\n",
    "        predicted_returns[stock] = predict_next_day_return(model, preprocessed_data[stock].loc[:date])\n",
    "\n",
    "    total_predicted_return = sum(predicted_returns.values())\n",
    "    allocations = {stock: predicted_return / total_predicted_return for stock, predicted_return in predicted_returns.items()}\n",
    "\n",
    "    next_day_values = {}\n",
    "    for stock, allocation in allocations.items():\n",
    "        next_day_close_price = stock_data[stock].loc[date:].iloc[1]['Close']\n",
    "        next_day_value = next_day_close_price * allocation * current_investment\n",
    "        next_day_values[stock] = next_day_value\n",
    "\n",
    "    current_investment = sum(next_day_values.values())\n",
    "    daily_portfolio_value.append(current_investment)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(investment_dates, daily_portfolio_value, label='Portfolio Value')\n",
    "plt.title(\"Dynamic Portfolio Performance Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value ($)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
